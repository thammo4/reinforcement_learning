{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c",
   "metadata": {},
   "source": [
    "### Lab: Value Iteration in a Grid World\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: December 11, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "\n",
    "Implement value iteration for a $4 \\times 3$ gridworld environment. This will measure the value of each state. A robot in this world can make discrete moves: one step up, down, left or right. These actions are deterministic, meaning that the action selected will be taken with probability 1. There is a terminal state with reward +1 in the bottom right corner. All other states have reward 0. The discount factor is 0.9. Use tolerance $\\theta=0.01$. Show all code and results.\n",
    "\n",
    "#### Total Points: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5956322-1af2-4a18-b65c-d98dc08454c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 1) **(POINTS: 2)** As part of your solution, create a GridWorld class with these attributes:\n",
    "\n",
    "- `nrows` : number of rows in the grid\n",
    "- `ncols` : number of columns in the grid\n",
    "\n",
    "and these methods:\n",
    "\n",
    "- `value_iteration()` with behavior described in [2] below\n",
    "- `get_reward()` : given the agent row and column, return the reward\n",
    "\n",
    "The class may include additional attributes and methods as well. \n",
    "\n",
    "Create an instance using the class, and call `nrows`, `ncols`, and `get_reward()` to verify correctness. \n",
    "\n",
    "You will not be graded on the implementation of `value_iteration()` for this problem.\n",
    "\n",
    "#### 2) **(POINTS: 8)** Here, you will be graded on the implementation of `value_iteration()`. \n",
    "Call `value_iteration()` to calculate and return the value function array. For each sweep over the states, have the function print out the intermediate array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd213107-d461-431c-b1e1-d1d3c099976d",
   "metadata": {},
   "source": [
    "#### Enter all code here (you may also use multiple cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338948a3-db77-4458-a6ed-a3f5e4aa3c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "858c5f68-7b54-459e-95f3-59697cfa6d23",
   "metadata": {},
   "source": [
    "#### 1) Create and test the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a43af-2be7-49d3-aec0-1934160bb61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb15497-6f08-4f3e-abef-43099f05fba7",
   "metadata": {},
   "source": [
    "#### 2) Run value iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922da11f-c12f-4535-8a8a-63cbcab3e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486efc92-9a71-4956-b877-b6b7cef13031",
   "metadata": {},
   "source": [
    "#### 3) **(POINTS: 2)** Based on the value function: After the agent has moved right or down, does it ever make sense for it to backtrack (move up or left)? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d310a-493c-4bcc-8328-c09c88116b0e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
