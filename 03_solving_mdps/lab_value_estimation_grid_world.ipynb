{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c",
   "metadata": {},
   "source": [
    "### Lab: Value Iteration in a Grid World\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: September 5, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "\n",
    "Implement value iteration for a $4 \\times 3$ gridworld environment. The actions are up, down, left and right. The actions are deterministic, meaning that the action selected will be taken with probability 1. There is a terminal state with reward +1 in the bottom right corner. All other rewards are 0. The discount factor is 0.9. Use tolerance $\\theta=0.01$.\n",
    "\n",
    "Your function should return an array with the estimated values for each state. For each sweep over the states, print out the intermediate array.\n",
    "\n",
    "**NOTE**: It is encouraged (but optional) create a GridWorld class that includes `value_iteration()` as a method. Then you would call that method to calculate and return the value function array.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4deb2d6-a0ea-46bb-b0a9-e3fc15482e49",
   "metadata": {},
   "source": [
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f89e37-d060-48ec-b1a6-809eba649178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
