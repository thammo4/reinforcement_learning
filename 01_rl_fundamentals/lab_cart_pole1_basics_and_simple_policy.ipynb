{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GBod1nv65dN"
   },
   "source": [
    "## Lab: Cart Pole using OpenAI gym  \n",
    "## Basics and Simple Policy\n",
    "\n",
    "### University of Virginia\n",
    "### Reinforcement Learning\n",
    "#### Last updated: August 21, 2023\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krpOsEbE_aTj"
   },
   "source": [
    "### Agent and Environment\n",
    "\n",
    "It is essential for the agent to have a way to get the next state and reward from the environment. \n",
    "\n",
    "Sometimes it is possible for the agent to interact with environment in real life, but often this is expensive / dangerous / impossible.\n",
    "\n",
    "We use models and simulators in this latter case.\n",
    "\n",
    "For this reason, the Gym package is useful in RL\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVwAKKjUBxFT"
   },
   "source": [
    "### Introduction to Gym\n",
    "\n",
    "We will work with [Gym](https://gym.openai.com/) from Open AI.\n",
    "\n",
    "Gym is a toolkit for developing and comparing RL algorithms.\n",
    "\n",
    "It comes with many pre-built environments.\n",
    "\n",
    "Users can build their own custom environments. See [here](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e#:~:text=8%20min%20read-,Create%20custom%20gym%20environments%20from%20scratch%20%E2%80%94%20A%20stock%20market%20example,Atari%20games%20to%20experiment%20with.) for example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUTU3338AvT9"
   },
   "source": [
    "### Cart Pole Problem\n",
    "\n",
    "The [**CartPole**](https://gym.openai.com/videos/2019-10-21--mqt8Qj1mwo/CartPole-v1/original.mp4) problem has a small state space and action space, so it's popular for illustrating ideas. \n",
    "\n",
    "Pole is attached to a cart on a frictionless track.\n",
    "\n",
    "Pole starts upright\n",
    "\n",
    "**Goal** is to keep pole from falling over\n",
    "\n",
    "Control system by applying **force** -1 or +1 to cart.\n",
    "\n",
    "**Reward** of +1 for each timestep the pole remains upright\n",
    "\n",
    "**Episode** ends when pole is more than 12 degrees from vertical, or cart moves more than 2.4 units from center\n",
    "\n",
    "CartPole-v0 defines *solving* as getting average reward of 195.0 over 100 consecutive trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./cartpole.png\" alt=\"drawing\" width=\"150\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rA_dd0h6Eoap"
   },
   "source": [
    "### Setup and First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgSNDjuzow2U"
   },
   "source": [
    "This notebook can be easily run on [Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ed_DyvHy6pbh"
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA4JgtuL5jC9"
   },
   "source": [
    "Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UcGLRi6F6vcQ"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "state = env.reset(seed=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtQFJsxj7aBj"
   },
   "source": [
    "Given the state, we take an action. The next state comes from the environment, which is encoded in `gym`.\n",
    "\n",
    "Components:   \n",
    "[0]: cart horizontal position (0.0 = center)  \n",
    "[1]: velocity (positive means right)  \n",
    "[2]: angle of the pole (0.0 = vertical)  \n",
    "[3]: pole's angular velocity (positive means clockwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M30S6Bf_6yNv",
    "outputId": "b0adbf2b-9267-416a-d7df-74f2277e1ed0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04225422, 0.02126478, 0.02520455, 0.00700802], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A5peNKiBXsh",
    "outputId": "59a30da4-be9d-4f8d-a178-8fd5dbf66b3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state space number of components\n",
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GkZmsIN7ky6"
   },
   "source": [
    "The action space consists of two options: \n",
    "\n",
    "[0]: move cart left   \n",
    "[1]: move cart right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySQ8EpsV7Ngr",
    "outputId": "bb78688d-b282-4338-a9ce-c229ed60906a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_68lpUuVCc-_"
   },
   "source": [
    "Let's take an action, draw a sample and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKFEIHjL7n7h",
    "outputId": "504c31ce-d526-4bfa-9842-ab4af59d7e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state [ 0.05521519  0.60560644  0.00854836 -0.84858215]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n"
     ]
    }
   ],
   "source": [
    "# move right\n",
    "action = 1\n",
    "\n",
    "# take a step and get next state, reward from environment\n",
    "state, reward, done, info = env.step(action)\n",
    "\n",
    "print('state', state)\n",
    "print('reward', reward)\n",
    "print('done', done)\n",
    "print('info', info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqxI0vej88Kh"
   },
   "source": [
    "**Reward and Episode**  \n",
    "\n",
    "For each time step that the cart keeps the pole balanced, it earns reward 1.\n",
    "\n",
    "If the pole tilts too much or if the cart moves off screen, `reward=0` and `done=True` (the episode will end).\n",
    "\n",
    "When the episode ends, a new episode may begin. The process learns cumulatively from each episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv5gKVde9pvQ"
   },
   "source": [
    "**Simple policy**:  \n",
    "\n",
    "When the pole leans left (negative angle), move left. When the pole leans right (positive angle), move right.\n",
    "\n",
    "Run many episodes and visualize their reward distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dREsiRKf9CbR"
   },
   "outputs": [],
   "source": [
    "def simple_policy(obs):\n",
    "    angle = obs[2]\n",
    "    return 0 if angle < 0 else 1\n",
    "\n",
    "num_episodes = 1000\n",
    "num_steps = 100\n",
    "rewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    ep_reward = 0\n",
    "    obs = env.reset()\n",
    "    for step in range(num_steps):\n",
    "        action = simple_policy(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        ep_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    rewards.append(ep_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "nzdjBfiA-yab",
    "outputId": "d19abbbd-da81-469a-b4b3-b070d5e98a9b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(rewards, vert=False)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rOaGhKK7mHg"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 1** Given this setup and simple policy what is the mean and maximum reward (roughly)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWTRqKtR7l74"
   },
   "source": [
    "**Question 2: Modified Policy.** Consider moving the cart for one step (either left or right), then reversing direction for one step, and then following the simple policy. Does  this change in policy increase the mean reward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnH4J3988wNe"
   },
   "source": [
    "**Question 3** What is the mean reward if you reverse the simple policy, moving left when the pole leans right, and moving right when the pole leans left? This is not a good idea, but it's instructive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4** Are there other simple changes you can make to increase the mean reward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_61H87rA_MT"
   },
   "source": [
    "---  \n",
    "\n",
    "### Wrapup\n",
    "\n",
    "This demo illustrated some basic ideas of reinforcement learning and got you started with OpenAI Gym. \n",
    "\n",
    "The simple policy is not able to solve the Cart Pole problem. \n",
    "\n",
    "We will revisit this example later, bringing in more tools for a better solution.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
